{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-28T17:05:11.497045200Z",
     "start_time": "2024-10-28T17:05:11.488064500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.visualization import plot_prediction_vs_real\n",
    "from experiments.graphs.graph_experiments import get_pignn_config, get_dataset, create_data_loaders\n",
    "from architecture.pignn.pignn import FlowPIGNN\n",
    "from architecture.pignn.deconv import DeConvNet, FCDeConvNet\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Evaluation methods for non-temporal methods\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def calculate_test_loss(model, test_loader, plot_examples=False):\n",
    "    with torch.no_grad():\n",
    "        test_losses = []\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            batch = batch.to(device)\n",
    "            x = batch.x.to(device).float()\n",
    "            pos = batch.pos.to(device).float()\n",
    "            ef = batch.edge_attr.to(device).float()\n",
    "            gf = batch.global_feats.to(device).float()\n",
    "            batch_size = gf.size(0)\n",
    "\n",
    "            if isinstance(model, FCDeConvNet):\n",
    "                x_cat = torch.cat((\n",
    "                    x.reshape(batch_size, -1),\n",
    "                    pos.reshape(batch_size, -1),\n",
    "                    ef.reshape(batch_size, -1),\n",
    "                    gf.reshape(batch_size, -1)\n",
    "                ), dim=-1)\n",
    "\n",
    "                pred = model(x_cat).float()\n",
    "                target = batch.y.to(device).reshape(-1, pred.size(1))\n",
    "            else:\n",
    "                pred = model(batch, torch.cat((x, pos), dim=-1), ef, gf)\n",
    "                target = batch.y.to(device).reshape(-1, pred.size(1))\n",
    "            test_loss = criterion(pred, target)\n",
    "\n",
    "            if plot_examples:\n",
    "                predictions = [\n",
    "                    pred[0, :].reshape(128, 128).cpu(),\n",
    "                    pred[16, :].reshape(128, 128).cpu(),\n",
    "                    pred[32, :].reshape(128, 128).cpu()\n",
    "                ]\n",
    "\n",
    "                targets = [\n",
    "                    target[0, :].reshape(128, 128).cpu(),\n",
    "                    target[16, :].reshape(128, 128).cpu(),\n",
    "                    target[32, :].reshape(128, 128).cpu()\n",
    "                ]\n",
    "                for j in range(3):\n",
    "                    plot_prediction_vs_real(predictions[j], targets[j], number=3*i+j)\n",
    "            test_losses.append(test_loss.item())\n",
    "\n",
    "        return np.mean(test_losses), np.std(test_losses)\n",
    "\n",
    "def evaluate_model(experiment_dir, plot_examples=False):\n",
    "    config_path = os.path.join(experiment_dir, 'config.json')\n",
    "    model_config = get_pignn_config()\n",
    "    config = load_config(config_path)\n",
    "    model = FlowPIGNN(**model_config, deconv_model=DeConvNet(1, [64, 128, 256, 1], output_size=128)).to(device) if config['use_graph'] else FCDeConvNet(212, 650, 656, 500).to(device)\n",
    "    model_path = os.path.join(experiment_dir, 'pignn_best.pt')\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    dataset = get_dataset(config['dataset_dirs'], False, 1)\n",
    "    _, _, test_loader = create_data_loaders(dataset, config['batch_size'], 1)\n",
    "    return calculate_test_loss(model, test_loader, plot_examples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-28T17:05:11.881992100Z",
     "start_time": "2024-10-28T17:05:11.880990700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate MSE for non-temporal methods\n",
    "base_dir = \"results/windmaps\"\n",
    "\n",
    "for experiment_name in os.listdir(base_dir):\n",
    "    experiment_dir = os.path.join(base_dir, experiment_name)\n",
    "\n",
    "    if os.path.isdir(experiment_dir):  # Check if it's a directory\n",
    "        try:\n",
    "            mse, std = evaluate_model(experiment_dir)\n",
    "            print(f\"Loaded model from {experiment_name} has MSE on test set: {mse} +- {std}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load model from {experiment_name}: {e}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Counting model params\n",
    "\n",
    "model_cfg = get_pignn_config()\n",
    "deconv_model = DeConvNet(1, [64, 128, 256, 1], output_size=128)\n",
    "pignn_model = FlowPIGNN(**model_cfg, deconv_model=deconv_model).to(device)\n",
    "\n",
    "fcn_model = FCDeConvNet(212, 650, 656, 500).to(device)\n",
    "\n",
    "def count_trainable_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Num params PIGNN model: {count_trainable_params(pignn_model)}\")\n",
    "print(f\"Num params FCN model: {count_trainable_params(fcn_model)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot wind speed maps for a specific model\n",
    "to_plot = [\n",
    "    \"D:\\\\AI2P\\\\repo\\\\experiments\\\\graphs\\\\results\\\\windmaps\\\\20241025174803_Case01_True_pignn_deconv_90_all_data\"\n",
    "]\n",
    "\n",
    "for experiment_dir in to_plot:\n",
    "    mse, std = evaluate_model(experiment_dir, plot_examples=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from architecture.windspeedLSTM.windspeedLSTM import WindSpeedLSTMDeConv, WindspeedLSTM\n",
    "image_size = 128\n",
    "seq_length = 50\n",
    "\n",
    "# Evaluation methods for temporal methods\n",
    "def prepare_temporal_model(experiment_dir):\n",
    "    config_path = os.path.join(experiment_dir, 'config.json')\n",
    "    model_config = get_pignn_config()\n",
    "    config = load_config(config_path)\n",
    "    is_direct_lstm = config['direct_lstm']\n",
    "\n",
    "\n",
    "    deconv_model = DeConvNet(1, [64, 128, 256, 1], output_size=image_size) if not is_direct_lstm else None\n",
    "    graph_model = FlowPIGNN(**model_config, deconv_model=deconv_model).to(device)\n",
    "    graph_model_path = os.path.join(experiment_dir, 'pignn_best.pt')\n",
    "    graph_model.load_state_dict(torch.load(graph_model_path))\n",
    "\n",
    "    temporal_model = WindSpeedLSTMDeConv(seq_length, [64, 128, 256, 1], image_size).to(\n",
    "        device) if is_direct_lstm else WindspeedLSTM(seq_length).to(device)\n",
    "    temporal_model_path = os.path.join(experiment_dir, 'unet_lstm_best.pt')\n",
    "    temporal_model.load_state_dict(torch.load(temporal_model_path))\n",
    "    embedding_size = (50, 10) if is_direct_lstm else (image_size, image_size)\n",
    "\n",
    "    dataset = get_dataset(config['dataset_dirs'], True, seq_length)\n",
    "    _, _, test_loader = create_data_loaders(dataset, config['batch_size'], seq_length)\n",
    "    return test_loader, graph_model, temporal_model, embedding_size\n",
    "\n",
    "def calculate_temporal_test_loss(test_loader, graph_model, temporal_model, embedding_size, output_size=(128, 128), plot_examples=False):\n",
    "    with torch.no_grad():\n",
    "        test_losses = []\n",
    "        for j, batch in enumerate(test_loader):\n",
    "            generated_img = []\n",
    "            target_img = []\n",
    "            for i, seq in enumerate(batch[0]):\n",
    "                # Process graphs in parallel at each timestep for the entire batch\n",
    "                seq = seq.to(device)\n",
    "                nf = torch.cat((seq.x.to(device), seq.pos.to(device)), dim=-1).float()\n",
    "                ef = seq.edge_attr.to(device).float()\n",
    "                gf = seq.global_feats.to(device).float()\n",
    "                graph_output = graph_model(seq, nf, ef, gf).reshape(-1, embedding_size[0], embedding_size[1])\n",
    "                generated_img.append(graph_output)\n",
    "                target_img.append(batch[1][i].y.to(device).reshape(-1, output_size[0], output_size[1]))\n",
    "\n",
    "            temporal_img = torch.stack(generated_img, dim=1)\n",
    "            output = temporal_model(temporal_img).flatten()\n",
    "            target = torch.stack(target_img, dim=1).flatten()\n",
    "            test_loss = criterion(output, target)\n",
    "\n",
    "            if plot_examples:\n",
    "                plot_prediction_vs_real(output[0, seq_length - 1].cpu(), target[0, seq_length - 1].cpu(), number=j+6)\n",
    "            test_losses.append(test_loss.item())\n",
    "    return np.mean(test_losses), np.std(test_losses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate MSE for temporal methods\n",
    "base_dir = \"results/temporal\"\n",
    "\n",
    "# Iterate through each experiment folder and load the model and config\n",
    "for experiment_name in os.listdir(base_dir):\n",
    "    experiment_dir = os.path.join(base_dir, experiment_name)\n",
    "\n",
    "    if os.path.isdir(experiment_dir):\n",
    "        try:\n",
    "            test_loader, graph_model, temporal_model, embedding_size = prepare_temporal_model(experiment_dir)\n",
    "            mse, std = calculate_temporal_test_loss(test_loader, graph_model, temporal_model, embedding_size)\n",
    "            print(f\"Loaded model from {experiment_name} has MSE on test set: {mse} +- {std}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load model from {experiment_name}: {e}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.visualization import animate_prediction_vs_real\n",
    "\n",
    "to_plot = [\n",
    "    \"D:\\\\AI2P\\\\repo\\\\experiments\\\\graphs\\\\results\\\\temporal\\\\20241026232226_Case01_False_pignn_lstm_deconv_30_50_case_01_sliding\"\n",
    "]\n",
    "\n",
    "for experiment_dir in to_plot:\n",
    "    test_loader, graph_model, temporal_model, embedding_size = prepare_temporal_model(experiment_dir)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        animation_length = 50\n",
    "        num = 0\n",
    "        for j, batch in enumerate(test_loader):\n",
    "            if num < 10:\n",
    "                generated_img = []\n",
    "                target_img = []\n",
    "                for i, seq in enumerate(batch[0]):\n",
    "                    # Process graphs in parallel at each timestep for the entire batch\n",
    "                    seq = seq.to(device)\n",
    "                    nf = torch.cat((seq.x.to(device), seq.pos.to(device)), dim=-1).float()\n",
    "                    ef = seq.edge_attr.to(device).float()\n",
    "                    gf = seq.global_feats.to(device).float()\n",
    "                    graph_output = graph_model(seq, nf, ef, gf).reshape(-1, embedding_size[0], embedding_size[1])\n",
    "                    generated_img.append(graph_output)\n",
    "                    target_img.append(batch[1][i].y.to(device).reshape(-1, 128, 128))\n",
    "\n",
    "                temporal_img = torch.stack(generated_img, dim=1)\n",
    "                output = temporal_model(temporal_img).reshape(-1, seq_length, 128, 128)\n",
    "                target = torch.stack(target_img, dim=1)\n",
    "\n",
    "                def animate_callback(i):\n",
    "                    return output[0, i].cpu(), target[0, i].cpu()\n",
    "                animate_prediction_vs_real(animate_callback, animation_length, f\"animation2_{j}\")\n",
    "                num += 1\n",
    "            else:\n",
    "                break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from utils.visualization import get_layout_file, add_imshow, add_windmills\n",
    "\n",
    "# Show that it fails to capture dynamics\n",
    "\n",
    "to_plot = [\n",
    "    \"D:\\\\AI2P\\\\repo\\\\experiments\\\\graphs\\\\results\\\\temporal\\\\20241026180328_Case01_False_pignn_unet_lstm_30_50_case_01_sliding\"\n",
    "]\n",
    "\n",
    "\n",
    "def plot_prediction_vs_real(target_1, predicted_1, target_50, predicted_50, case=1, number=0):\n",
    "    layout_file = get_layout_file(case)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 12))  # 2 rows, 2 columns\n",
    "\n",
    "    # Plot target\n",
    "    img1 = add_imshow(fig, axs[0, 0], target_1, color_bar=False)\n",
    "    axs[0, 0].set_title('Target t=1')\n",
    "    axs[0, 0].set_aspect('equal', adjustable='box')\n",
    "    add_windmills(axs[0, 0], layout_file)\n",
    "\n",
    "    # Plot predicted\n",
    "    add_imshow(fig, axs[0, 1], predicted_1, color_bar=False)\n",
    "    axs[0, 1].set_title('Predicted t=1')\n",
    "    axs[0, 1].set_aspect('equal', adjustable='box')\n",
    "    add_windmills(axs[0, 1], layout_file)\n",
    "\n",
    "    cbar_ax = fig.add_axes([1.02, 0, 0.02, 1])  # [left, bottom, width, height]\n",
    "    fig.colorbar(img1, cax=cbar_ax, orientation='vertical')\n",
    "\n",
    "    # Plot target\n",
    "    img1 = add_imshow(fig, axs[1, 0], target_50, color_bar=False)\n",
    "    axs[1, 0].set_title('Target t=50')\n",
    "    axs[1, 0].set_aspect('equal', adjustable='box')\n",
    "    add_windmills(axs[1, 0], layout_file)\n",
    "\n",
    "    # Plot predicted\n",
    "    add_imshow(fig, axs[1, 1], predicted_50, color_bar=False)\n",
    "    axs[1, 1].set_title('Predicted t=50')\n",
    "    axs[1, 1].set_aspect('equal', adjustable='box')\n",
    "    add_windmills(axs[1, 1], layout_file)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'predictions_vs_targets_{number}.pdf', format='pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for experiment_dir in to_plot:\n",
    "    test_loader, graph_model, temporal_model, embedding_size = prepare_temporal_model(experiment_dir)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        animation_length = 50\n",
    "        num = 0\n",
    "        for j, batch in enumerate(test_loader):\n",
    "            if j < 10:\n",
    "                generated_img = []\n",
    "                target_img = []\n",
    "                for i, seq in enumerate(batch[0]):\n",
    "                    # Process graphs in parallel at each timestep for the entire batch\n",
    "                    seq = seq.to(device)\n",
    "                    nf = torch.cat((seq.x.to(device), seq.pos.to(device)), dim=-1).float()\n",
    "                    ef = seq.edge_attr.to(device).float()\n",
    "                    gf = seq.global_feats.to(device).float()\n",
    "                    graph_output = graph_model(seq, nf, ef, gf).reshape(-1, embedding_size[0], embedding_size[1])\n",
    "                    generated_img.append(graph_output)\n",
    "                    target_img.append(batch[1][i].y.to(device).reshape(-1, 128, 128))\n",
    "\n",
    "                temporal_img = torch.stack(generated_img, dim=1)\n",
    "                output = temporal_model(temporal_img).reshape(-1, seq_length, 128, 128)\n",
    "                target = torch.stack(target_img, dim=1)\n",
    "                print(output.shape)\n",
    "                print(target.shape)\n",
    "\n",
    "                plot_prediction_vs_real(target[0, 0].cpu(), output[0, 0].cpu(), target[0, 49].cpu(), output[0, 49].cpu(), number=100+j)\n",
    "            else:\n",
    "                break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
